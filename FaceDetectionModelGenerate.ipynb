
import os
import cv2
import numpy as np
import gc
import tensorflow as tf
import torch
from tensorflow.keras import layers, models
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# WIDER FACE 데이터셋 경로
image_dir = 'WIDER_train/images'

# 이미지와 주석 정보
images = []
bboxes = []

# 배치 크기 설정
batch_size = 32

# 이미지 디렉토리 내의 모든 폴더와 파일을 순회
for foldername in os.listdir(image_dir):
    folder_path = os.path.join(image_dir, foldername)
    
    if not os.path.isdir(folder_path):
        continue
    
    for filename in os.listdir(folder_path):
        if filename.endswith('.jpg'):
            print(filename)
            image_path = os.path.join(folder_path, filename)
            image = cv2.imread(image_path)
            
            if image is None:
                print(f"Warning: Unable to read image {image_path}")
                continue  # 이미지가 없으면 건너뛰기
            
            images.append(image)
            
            # 해당 이미지의 경계 상자 좌표 파일 읽기
            txt_filename = filename.replace('.jpg', '.txt')
            bbox_path = os.path.join(folder_path, txt_filename)
            
            if os.path.exists(bbox_path):
                with open(bbox_path, 'r') as f:
                    box_list = [list(map(int, line.strip().split())) for line in f.readlines()]
                    bboxes.append(box_list)

# 데이터 전처리
def preprocess_data(images, bboxes, batch_size):
    gc.collect()
    X = []
    labels = []  # y를 labels로 변경
    
    for img, box_list in zip(images, bboxes):
        for box in box_list:
            box_x, box_y, w, h = box  # (x1, y1, w, h)
            # 경계 상자가 이미지 내에 있는지 확인
            box_x = max(0, box_x)
            box_y = max(0, box_y)
            w = min(w, img.shape[1] - box_x)
            h = min(h, img.shape[0] - box_y)
            
            # 얼굴 영역 추출
            if w > 0 and h > 0:  # 얼굴 영역이 비어있지 않은 경우
                face = img[int(box_y):int(box_y+h), int(box_x):int(box_x+w)]
                
                if face.size > 0:  # face가 비어있지 않은 경우
                    face = cv2.resize(face, (224, 224))  # MobileNetV2 입력 크기로 조정
                    X.append(face)
                    labels.append([box_x, box_y, w, h])  # 경계 상자 좌표
                    
                    # 배치 크기만큼 데이터가 쌓이면 반환
                    if len(X) == batch_size:
                        yield np.array(X), np.array(labels)
                        X, labels = [], []  # 데이터 초기화

    # 남은 데이터 반환
    if X and labels:
        yield np.array(X), np.array(labels)

# 데이터셋 생성
X_full, y_full = [], []
for batch_X, batch_y in preprocess_data(images, bboxes, batch_size):
    X_full.append(batch_X)
    y_full.append(batch_y)

X_full = np.concatenate(X_full)
y_full = np.concatenate(y_full)

# 데이터셋 분할
X_train, X_val, y_train, y_val = train_test_split(X_full, y_full, test_size=0.2, random_state=42)

# 모델 정의
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base_model.trainable = False  # 전이 학습을 위해 기본 모델의 가중치 고정

model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(128, activation='relu'),  # 추가적인 레이어
    layers.Dense(4)  # 경계 상자 좌표 (x, y, width, height)
])

# 모델 컴파일
model.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error', metrics=['mae'])

# 데이터 로딩 최적화 위해 데이터를 한 번에 메모리에 로드하지 않고, 배치 단위로 로드하는 제너레이터를 사용
datagen = ImageDataGenerator(rescale=1./255)
train_generator = datagen.flow(X_train, y_train, batch_size=32)
val_generator = datagen.flow(X_val, y_val, batch_size=32)

# 모델 학습
model.fit(train_generator, validation_data=val_generator, epochs=20)

# 모델 저장
model.save('face_detection_model.keras')
